{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lassana Diabira\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"Training_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.sample(train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"Test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_characteristics(df): \n",
    "    job_type=[]\n",
    "    job_title=[]\n",
    "    employer_title=[]\n",
    "    employer_sector_title=[]\n",
    "    job_sector_title=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        data=df.iloc[i]\n",
    "        types=data[\"job_type\"]\n",
    "        title=data[\"job_title\"]\n",
    "        em_title=data[\"employer_title\"]\n",
    "        em_sec_title=data[\"employer_sector_title\"]\n",
    "        job_sec_title=data[\"job_sector_title\"]\n",
    "        job_type.append(types)\n",
    "        job_title.append(title)\n",
    "        employer_title.append(em_title)\n",
    "        employer_sector_title.append(em_sec_title)\n",
    "        job_sector_title.append(job_sec_title)\n",
    "    d={}\n",
    "    #d[\"job_title\"]=job_title\n",
    "    #d[\"employer_title\"]=employer_title\n",
    "    d[\"employer_sector_title\"]=employer_sector_title\n",
    "    d[\"job_sector_title\"]=job_sector_title\n",
    "    a=pd.DataFrame(d)\n",
    "    data=pd.get_dummies(a)\n",
    "    b=pd.get_dummies(job_type)\n",
    "    result = pd.concat([data, b], axis=1, sort=False)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_user(user):\n",
    "    jobtitles=list(user[\"job_title\"].values)\n",
    "    emtitles=list(user[\"employer_title\"].values)\n",
    "    jobsectitles=list(user[\"job_sector_title\"].values)\n",
    "    emsectitles=list(user[\"employer_sector_title\"].values)\n",
    "    a=\"\"\n",
    "    for k in range(len(jobtitles)):\n",
    "        a+=jobtitles[k]+\" \"\n",
    "        a+=emtitles[k]+\" \"\n",
    "        a+=jobsectitles[k]+\" \"\n",
    "        #a+=emsectitles[k]+\" \"\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_characteristics(df):\n",
    "    corpus=[]\n",
    "    gender=[]\n",
    "    ethnicity=[]\n",
    "    school_type=[]\n",
    "    right_to_work_uk=[]\n",
    "    university_name=[]\n",
    "    university_type=[]\n",
    "    course_includes_industrial_placement=[]\n",
    "    degree_subject_name=[]\n",
    "    user_preference=[]\n",
    "    job_types=list(set(df[\"job_type\"].values))\n",
    "    em_sectors=list(set(df[\"employer_sector_title\"].values))\n",
    "    job_sectors=list(set(df[\"job_sector_title\"].values))\n",
    "    count_job_types=[[] for i in range(len(job_types))]\n",
    "    count_job_sectors=[[] for i in range(len(job_sectors))]\n",
    "    count_em_sectors=[[] for i in range(len(em_sectors))]\n",
    "    nb_em_sector=[]\n",
    "    nb_job_sector=[]\n",
    "    job_type=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        data=df.iloc[i]\n",
    "        user=data[\"user_id\"]\n",
    "        user_data=df[df[\"user_id\"]==user]\n",
    "        user_job_type=dict(Counter(list(user_data[\"job_type\"].values)))\n",
    "        user_job_sectors=dict(Counter(list(user_data[\"job_sector_title\"].values)))\n",
    "        user_em_sectors=dict(Counter(list(user_data[\"employer_sector_title\"].values)))\n",
    "        user_em_sector=len(list(set(list(user_data[\"employer_sector_title\"].values))))\n",
    "        user_job_sector=len(list(set(list(user_data[\"job_sector_title\"].values))))\n",
    "        for i in range(len(count_job_types)):\n",
    "            try:\n",
    "                count_job_types[i].append(user_job_type[i])\n",
    "            except:\n",
    "                count_job_types[i].append(0)\n",
    "        for i in range(len(count_job_sectors)):\n",
    "            try:\n",
    "                count_job_sectors[i].append(user_job_sectors[i])\n",
    "            except:\n",
    "                count_job_sectors[i].append(0)\n",
    "        for i in range(len(count_em_sectors)):\n",
    "            try:\n",
    "                count_em_sectors[i].append(user_em_sectors[i])\n",
    "            except:\n",
    "                count_em_sectors[i].append(0)\n",
    "        sex=data[\"gender\"]\n",
    "        jobtype=data[\"job_type\"]\n",
    "        eth=data[\"ethnicity\"]\n",
    "        school=data[\"school_type\"]\n",
    "        placement=data[\"course_includes_industrial_placement\"]\n",
    "        right=data[\"right_to_work_uk\"]\n",
    "        uni=data[\"university_name\"]\n",
    "        uni_type=data[\"university_type\"]\n",
    "        subname=data[\"degree_subject_name\"]\n",
    "        pref=data[\"user_preference\"]\n",
    "        title=data[\"job_title\"]\n",
    "        em_title=data[\"employer_title\"]\n",
    "        em_sec_title=data[\"employer_sector_title\"]\n",
    "        job_sec_title=data[\"job_sector_title\"]\n",
    "        if sex==\"F\":\n",
    "            sex=\"Female\"\n",
    "        elif sex==\"M\":\n",
    "            sex=\"Male\"\n",
    "        if placement==True:\n",
    "            placement=1\n",
    "        elif placement==False:\n",
    "            placement=-1\n",
    "        else:\n",
    "            placement=0\n",
    "        if right==True:\n",
    "            right=1\n",
    "        elif right==False:\n",
    "            right=-1\n",
    "        else:\n",
    "            right=0\n",
    "        if type(pref) is float:\n",
    "            pref=\"\"\n",
    "        if type(subname) is float:\n",
    "            subname=\"\"\n",
    "        nb_em_sector.append(user_em_sector)\n",
    "        nb_job_sector.append(user_job_sector)\n",
    "        gender.append(sex)\n",
    "        ethnicity.append(eth)\n",
    "        school_type.append(school)\n",
    "        course_includes_industrial_placement.append(placement)\n",
    "        right_to_work_uk.append(right)\n",
    "        university_type.append(uni_type)\n",
    "        #degree_subject_name.append(subname)\n",
    "        #user_preference.append(pref)\n",
    "        job_type.append(jobtype)\n",
    "        corpus.append(pref+subname+\" \"+get_data_for_user(user_data))\n",
    "    d={}\n",
    "    for i in range(len(count_job_sectors)):\n",
    "        d['count_job_sectors_'+str(i)]=count_job_sectors[i]\n",
    "    for i in range(len(count_em_sectors)):\n",
    "        d['count_em_sectors_'+str(i)]=count_em_sectors[i]\n",
    "    for i in range(len(count_job_types)):\n",
    "        d['count_job_types_'+str(i)]=count_job_types[i]\n",
    "    d[\"gender\"]=gender\n",
    "    d[\"job_type\"]=job_type\n",
    "    d[\"nb_em_sector\"]=nb_em_sector\n",
    "    d[\"nb_job_sector\"]=nb_job_sector\n",
    "    d[\"right_to_work_uk\"]=right_to_work_uk\n",
    "    d[\"ethnicity\"]=ethnicity\n",
    "    #d[\"degree_subject_name\"]=degree_subject_name\n",
    "    d[\"school_type\"]=school_type\n",
    "    #d[\"user_preference\"]=user_preference\n",
    "    d[\"course_includes_industrial_placement\"]=course_includes_industrial_placement\n",
    "    a=pd.DataFrame(d)\n",
    "    data=pd.get_dummies(a)\n",
    "    b=pd.get_dummies(university_type)\n",
    "    result = pd.concat([data, b], axis=1, sort=False)\n",
    "    vectorizer = CountVectorizer(max_df=1.0, min_df=3)\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    col=vectorizer.get_feature_names()\n",
    "    donnees=X.toarray()\n",
    "    print(X.shape)\n",
    "    donnee=pd.DataFrame(donnees, columns=col)\n",
    "    final=pd.concat([result, donnee], axis=1)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_characteristics=get_user_characteristics(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_characteristics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job_characteristics=get_job_characteristics(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job_characteristics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_info(df):\n",
    "    user_info=[]\n",
    "    d={}\n",
    "    x=train[[\"user_id\",\"job_title\",\"employer_title\",\"job_sector_title\",\"job_description\",\n",
    "             \"employer_sector_title\",\"employer_description\"]]\n",
    "    n=df.shape[0]\n",
    "    for i in range(n):\n",
    "        if i%5000==0:\n",
    "            print(\"progress: \",i/n)\n",
    "        data=df.iloc[i]\n",
    "        user_id=data[\"user_id\"]\n",
    "        try:\n",
    "            a=d[str(user_id)]\n",
    "        except:\n",
    "            y=x[x[\"user_id\"]==user_id]\n",
    "            job_titles=y[\"job_title\"].values\n",
    "            job_sector_title=y[\"job_sector_title\"].values\n",
    "            description=y[\"job_description\"].values\n",
    "            em_titles=y[\"employer_title\"].values\n",
    "            em_sector_title=y[\"employer_sector_title\"].values\n",
    "            em_description=y[\"employer_description\"].values\n",
    "            university_name=data[\"university_name\"]\n",
    "            degree_subject_name=data[\"degree_subject_name\"]\n",
    "            user_preference=data[\"user_preference\"]\n",
    "            ethnicity=data[\"ethnicity\"]\n",
    "            school_type=data[\"school_type\"]\n",
    "            if type(user_preference) is float:\n",
    "                user_preference=\"\"\n",
    "            if type(university_name) is float:\n",
    "                university_name=\"\"\n",
    "            if type(degree_subject_name) is float:\n",
    "                degree_subject_name=\"\"\n",
    "            if type(ethnicity) is float:\n",
    "                ethnicity=\"\"\n",
    "            if type(school_type) is float:\n",
    "                school_type=\"\"\n",
    "            user_preference=user_preference+\" \"\n",
    "            user_preference=user_preference *3\n",
    "            degree_subject_name=degree_subject_name+\" \"\n",
    "            degree_subject_name=degree_subject_name *3\n",
    "            a=\"\"\n",
    "            a+=university_name+\" \"\n",
    "            a+=degree_subject_name+\" \"\n",
    "            a+=user_preference+\" \"\n",
    "            a+=ethnicity+\" \"\n",
    "            a+=school_type+\" \"\n",
    "            for k in range(len(job_titles)):\n",
    "                a+=job_titles[k]+\" \"\n",
    "                a+=job_sector_title[k]+\" \"\n",
    "                a+=description[k]+\" \"\n",
    "                a+=em_titles[k]+\" \"\n",
    "                a+=em_sector_title[k]+\" \"\n",
    "                a+=em_description[k]+\" \"\n",
    "            a=a.replace(\"Graduate\",\"\").replace(\"Programme\",\"\").replace(\"  \",\" \").replace(\"&\",\"\")\n",
    "            d[str(user_id)]=a\n",
    "        user_info.append(a)\n",
    "    return user_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress:  0.0\n",
      "progress:  0.05\n",
      "progress:  0.1\n",
      "progress:  0.15\n",
      "progress:  0.2\n",
      "progress:  0.25\n",
      "progress:  0.3\n",
      "progress:  0.35\n",
      "progress:  0.4\n",
      "progress:  0.45\n",
      "progress:  0.5\n",
      "progress:  0.55\n",
      "progress:  0.6\n",
      "progress:  0.65\n",
      "progress:  0.7\n",
      "progress:  0.75\n",
      "progress:  0.8\n",
      "progress:  0.85\n",
      "progress:  0.9\n",
      "progress:  0.95\n"
     ]
    }
   ],
   "source": [
    "train_user_info=get_user_info(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_user_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_user(x,df):\n",
    "    n=len(x)\n",
    "    res=[]\n",
    "    d={}\n",
    "    for i,content in enumerate(x):\n",
    "        if i%5000==0:\n",
    "            print(\"progress : \",i/n)\n",
    "        data=df.iloc[i]\n",
    "        user_id=data[\"user_id\"]\n",
    "        try:\n",
    "            y=d[str(user_id)]\n",
    "        except:\n",
    "            content=content.replace(\",\",\"\").replace(\"-\",\" \").replace(\"  \",\" \").replace(\"&eacute;\",\"e\")\n",
    "            content=content.replace(\"(\",\"\").replace(\")\",\"\").replace(\" - \",\" \").replace(\" / \",\" \").replace(\"/\",\" \").replace(\"   \",\"\")\n",
    "            content=content.replace(\"&bull;\",\"\\r\\n \").replace(\"bull;\",\"\\r\\n \").replace(\"\\r\\r\\n\\t\",\" \").replace(\"\\r\\r\\n\",\" \")\n",
    "            content=content.replace(\"\\r\\r\\n\\r\\r\\n\",\" \").replace(\"...\",\" \").replace(\"&#39;s\",\"\").replace(\":\",\"\")\n",
    "            content=content.replace(\"&eacute;\",\"e\").replace(\"&lsquo;\",\"\").replace(\"lsquo;\",\"\").replace(\"&#39;\",\"\").replace(\"#39;s\",\"\")\n",
    "            content=content.replace(\"&nbsp;\",\" \").replace(\"nbsp;\",\" \").replace(\"&#39;\",\"\").replace(\"amp;\",\"\").replace(\"&middot;\",\"\")\n",
    "            content=content.replace(\".\",\" \").replace(\",\",\"\").replace(\"?\",\" \").replace(\"!\",\"\").replace(\"  \",\" \").replace(\"middot;\",\"\")\n",
    "            content=content.replace(\"&rsquo;\",\"\").replace(\"rsquo;\",\" \").replace(\"\\t\",\" \").replace(\"\\r\\n\\r\\n\",\"\").replace(\" \\r\\n \",\"\")\n",
    "            content=content.replace(\"&ndash;\",\" \").replace(\"ndash;\",\" \").replace(\"\\r\\n\\r\\n\",\" \").replace(\" \\r\\n \",\" \").replace(\"\\r\\n\",\" \")\n",
    "            content=content.replace(\"\\r\",\" \").replace(\"  \",\"\").replace(\"   \",\"\").replace(\"  \",\"\").replace(\"   \",\"\")\n",
    "            content=content.replace(\"(\",\"\").replace(\")\",\"\").replace(\" - \",\" \").replace(\" / \",\" \").replace(\"/\",\" \").replace(\"   \",\"\")\n",
    "            content=re.sub('<.*?>',\"\",content , flags=re.DOTALL)\n",
    "            content=content.replace(\"&ldquo;\",\"\").replace(\"ldquo;\",\"\").replace(\"&rdquo;\",\"\").replace(\"rdquo;\",\"\")\n",
    "            try:\n",
    "                content=''.join([i for i in content if not i.isdigit()])\n",
    "            except:\n",
    "                pass\n",
    "            content=content.split(\" \")\n",
    "            y=[]\n",
    "            for i in content:\n",
    "                if len(i)>1:\n",
    "                    y.append(i.lower())\n",
    "            d[str(user_id)]=y\n",
    "        res.append(y)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress :  0.0\n",
      "progress :  0.05\n",
      "progress :  0.1\n",
      "progress :  0.15\n",
      "progress :  0.2\n",
      "progress :  0.25\n",
      "progress :  0.3\n",
      "progress :  0.35\n",
      "progress :  0.4\n",
      "progress :  0.45\n",
      "progress :  0.5\n",
      "progress :  0.55\n",
      "progress :  0.6\n",
      "progress :  0.65\n",
      "progress :  0.7\n",
      "progress :  0.75\n",
      "progress :  0.8\n",
      "progress :  0.85\n",
      "progress :  0.9\n",
      "progress :  0.95\n"
     ]
    }
   ],
   "source": [
    "clean_train_user_info=clean_user(train_user_info, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_info(df):\n",
    "    job_info=[]\n",
    "    d={}\n",
    "    for i in range(df.shape[0]):\n",
    "        data=df.iloc[i]\n",
    "        job_id=data[\"job_id\"]\n",
    "        try:\n",
    "            a=d[str(job_id)]\n",
    "        except:\n",
    "            title=data[\"job_title\"]\n",
    "            job_sector_title=data[\"job_sector_title\"]\n",
    "            description=data[\"job_description\"]\n",
    "            em_title=data[\"employer_title\"]\n",
    "            em_sector_title=data[\"employer_sector_title\"]\n",
    "            em_description=data[\"employer_description\"]\n",
    "            a=\"\"\n",
    "            a+=title+\" \"\n",
    "            a+=job_sector_title+\" \"\n",
    "            a+=description+\" \"\n",
    "            a+=em_title+\" \"\n",
    "            a+=em_sector_title+\" \"\n",
    "            a+=em_description\n",
    "            d[str(job_id)]=a\n",
    "        job_info.append(a)\n",
    "    return job_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_job_info=get_job_info(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_job_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x,df):\n",
    "    res=[]\n",
    "    n=len(x)\n",
    "    d={}\n",
    "    for i,content in enumerate(x):\n",
    "        if i%5000==0:\n",
    "            print(\"progress : \",i/n)\n",
    "        data=df.iloc[i]\n",
    "        job_id=data[\"job_id\"]\n",
    "        try:\n",
    "            y=d[str(job_id)]\n",
    "        except:\n",
    "            content=content.replace(\",\",\"\").replace(\"-\",\" \").replace(\"  \",\" \").replace(\"&eacute;\",\"e\")\n",
    "            content=content.replace(\"(\",\"\").replace(\")\",\"\").replace(\" - \",\" \").replace(\" / \",\" \").replace(\"/\",\" \").replace(\"   \",\"\")\n",
    "            content=content.replace(\"&bull;\",\"\\r\\n \").replace(\"bull;\",\"\\r\\n \").replace(\"\\r\\r\\n\\t\",\" \").replace(\"\\r\\r\\n\",\" \")\n",
    "            content=content.replace(\"\\r\\r\\n\\r\\r\\n\",\" \").replace(\"...\",\" \").replace(\"&#39;s\",\"\").replace(\":\",\"\")\n",
    "            content=content.replace(\"&eacute;\",\"e\").replace(\"&lsquo;\",\"\").replace(\"lsquo;\",\"\").replace(\"&#39;\",\"\").replace(\"#39;s\",\"\")\n",
    "            content=content.replace(\"&nbsp;\",\" \").replace(\"nbsp;\",\" \").replace(\"&#39;\",\"\").replace(\"amp;\",\"\").replace(\"&middot;\",\"\")\n",
    "            content=content.replace(\".\",\" \").replace(\",\",\"\").replace(\"?\",\" \").replace(\"!\",\"\").replace(\"  \",\" \").replace(\"middot;\",\"\")\n",
    "            content=content.replace(\"&rsquo;\",\"\").replace(\"rsquo;\",\" \").replace(\"\\t\",\" \").replace(\"\\r\\n\\r\\n\",\"\").replace(\" \\r\\n \",\"\")\n",
    "            content=content.replace(\"&ndash;\",\" \").replace(\"ndash;\",\" \").replace(\"\\r\\n\\r\\n\",\" \").replace(\" \\r\\n \",\" \").replace(\"\\r\\n\",\" \")\n",
    "            content=content.replace(\"\\r\",\" \").replace(\"  \",\"\").replace(\"   \",\"\").replace(\"  \",\"\").replace(\"   \",\"\")\n",
    "            content=content.replace(\"(\",\"\").replace(\")\",\"\").replace(\" - \",\" \").replace(\" / \",\" \").replace(\"/\",\" \").replace(\"   \",\"\")\n",
    "            content=re.sub('<.*?>',\"\",content , flags=re.DOTALL)\n",
    "            content=content.replace(\"&ldquo;\",\"\").replace(\"ldquo;\",\"\").replace(\"&rdquo;\",\"\").replace(\"rdquo;\",\"\")\n",
    "            try:\n",
    "                content=''.join([i for i in content if not i.isdigit()])\n",
    "            except:\n",
    "                pass\n",
    "            content=content.split(\" \")\n",
    "            y=[]\n",
    "            for i in content:\n",
    "                if len(i)>1:\n",
    "                    y.append(i.lower())\n",
    "            d[str(job_id)]=y\n",
    "        res.append(y)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress :  0.0\n",
      "progress :  0.05\n",
      "progress :  0.1\n",
      "progress :  0.15\n",
      "progress :  0.2\n",
      "progress :  0.25\n",
      "progress :  0.3\n",
      "progress :  0.35\n",
      "progress :  0.4\n",
      "progress :  0.45\n",
      "progress :  0.5\n",
      "progress :  0.55\n",
      "progress :  0.6\n",
      "progress :  0.65\n",
      "progress :  0.7\n",
      "progress :  0.75\n",
      "progress :  0.8\n",
      "progress :  0.85\n",
      "progress :  0.9\n",
      "progress :  0.95\n"
     ]
    }
   ],
   "source": [
    "cleaned_train_job_info=clean(train_job_info,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_job(x, df):\n",
    "    res=[]\n",
    "    n=len(x)\n",
    "    d={}\n",
    "    with open('stopwords.txt') as stopfile:\n",
    "        stopwords = stopfile.read()\n",
    "        stop = stopwords.split()\n",
    "    for i,job in enumerate(x):\n",
    "        if i%5000==0:\n",
    "            print(\"progress : \",i/n)\n",
    "        data=df.iloc[i]\n",
    "        job_id=data[\"job_id\"]\n",
    "        try:\n",
    "            a=d[str(job_id)]\n",
    "        except:\n",
    "            a=[]\n",
    "            for word in job:\n",
    "                if word not in stop:\n",
    "                    a.append(word)\n",
    "            d[str(job_id)]=a\n",
    "        res.append(a)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_user(x, df):\n",
    "    res=[]\n",
    "    n=len(x)\n",
    "    d={}\n",
    "    with open('stopwords.txt') as stopfile:\n",
    "        stopwords = stopfile.read()\n",
    "        stop = stopwords.split()\n",
    "    for i,user in enumerate(x):\n",
    "        if i%5000==0:\n",
    "            print(\"progress : \",i/n)\n",
    "        data=df.iloc[i]\n",
    "        user_id=data[\"user_id\"]\n",
    "        try:\n",
    "            a=d[str(user_id)]\n",
    "        except:\n",
    "            a=[]\n",
    "            for word in user:\n",
    "                if word not in stop:\n",
    "                    a.append(word)\n",
    "            d[str(user_id)]=a\n",
    "        res.append(a)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress :  0.0\n",
      "progress :  0.05\n",
      "progress :  0.1\n",
      "progress :  0.15\n",
      "progress :  0.2\n",
      "progress :  0.25\n",
      "progress :  0.3\n",
      "progress :  0.35\n",
      "progress :  0.4\n",
      "progress :  0.45\n",
      "progress :  0.5\n",
      "progress :  0.55\n",
      "progress :  0.6\n",
      "progress :  0.65\n",
      "progress :  0.7\n",
      "progress :  0.75\n",
      "progress :  0.8\n",
      "progress :  0.85\n",
      "progress :  0.9\n",
      "progress :  0.95\n"
     ]
    }
   ],
   "source": [
    "train_clean=remove_stopwords_job(cleaned_train_job_info,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress :  0.0\n",
      "progress :  0.05\n",
      "progress :  0.1\n",
      "progress :  0.15\n",
      "progress :  0.2\n",
      "progress :  0.25\n",
      "progress :  0.3\n",
      "progress :  0.35\n",
      "progress :  0.4\n",
      "progress :  0.45\n",
      "progress :  0.5\n",
      "progress :  0.55\n",
      "progress :  0.6\n",
      "progress :  0.65\n",
      "progress :  0.7\n",
      "progress :  0.75\n",
      "progress :  0.8\n",
      "progress :  0.85\n",
      "progress :  0.9\n",
      "progress :  0.95\n"
     ]
    }
   ],
   "source": [
    "train_user_clean=remove_stopwords_user(clean_train_user_info,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occurence_job(x,df):\n",
    "    res=[]\n",
    "    n=len(x)\n",
    "    d={}\n",
    "    for i,job in enumerate(x):\n",
    "        if i%5000==0:\n",
    "            print(\"progress : \",i/n)\n",
    "        data=df.iloc[i]\n",
    "        job_id=data[\"job_id\"]\n",
    "        try:\n",
    "            a=d[str(job_id)]\n",
    "        except:\n",
    "            a=dict(Counter(job))\n",
    "            d[str(job_id)]=a\n",
    "        res.append(a)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occurence_user(x,df):\n",
    "    res=[]\n",
    "    n=len(x)\n",
    "    d={}\n",
    "    for i,user in enumerate(x):\n",
    "        if i%5000==0:\n",
    "            print(\"progress : \",i/n)\n",
    "        data=df.iloc[i]\n",
    "        user_id=data[\"user_id\"]\n",
    "        try:\n",
    "            a=d[str(user_id)]\n",
    "        except:\n",
    "            a=dict(Counter(user))\n",
    "            d[str(user_id)]=a\n",
    "        res.append(a)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress :  0.0\n",
      "progress :  0.05\n",
      "progress :  0.1\n",
      "progress :  0.15\n",
      "progress :  0.2\n",
      "progress :  0.25\n",
      "progress :  0.3\n",
      "progress :  0.35\n",
      "progress :  0.4\n",
      "progress :  0.45\n",
      "progress :  0.5\n",
      "progress :  0.55\n",
      "progress :  0.6\n",
      "progress :  0.65\n",
      "progress :  0.7\n",
      "progress :  0.75\n",
      "progress :  0.8\n",
      "progress :  0.85\n",
      "progress :  0.9\n",
      "progress :  0.95\n"
     ]
    }
   ],
   "source": [
    "occurences=get_occurence_job(train_clean,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress :  0.0\n",
      "progress :  0.05\n",
      "progress :  0.1\n",
      "progress :  0.15\n",
      "progress :  0.2\n",
      "progress :  0.25\n",
      "progress :  0.3\n",
      "progress :  0.35\n",
      "progress :  0.4\n",
      "progress :  0.45\n",
      "progress :  0.5\n",
      "progress :  0.55\n",
      "progress :  0.6\n",
      "progress :  0.65\n",
      "progress :  0.7\n",
      "progress :  0.75\n",
      "progress :  0.8\n",
      "progress :  0.85\n",
      "progress :  0.9\n",
      "progress :  0.95\n"
     ]
    }
   ],
   "source": [
    "train_user_occurences=get_occurence_user(train_user_clean,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_job(occurences, jobs, vector_size,df):\n",
    "    vector=[]\n",
    "    d={}\n",
    "    model = Word2Vec.load('model.bin')\n",
    "    nb=len(jobs)\n",
    "    for i,job in enumerate(jobs):\n",
    "        if i%10000==0:\n",
    "            print(\"progress : \",i/nb )\n",
    "        data=df.iloc[i]\n",
    "        job_id=data[\"job_id\"]\n",
    "        try:\n",
    "            res=d[str(job_id)]\n",
    "        except:\n",
    "            res=np.zeros(vector_size,)\n",
    "            n=sum(list(occurences[i].values()))\n",
    "            job_unique=list(set(job))\n",
    "            for word in job_unique:\n",
    "                try:\n",
    "                    a=model[word]\n",
    "                except:\n",
    "                    #print(word)\n",
    "                    a=None\n",
    "                if a is not None:\n",
    "                    count=occurences[i][word]\n",
    "                    w=count/n\n",
    "                    res+=w*a\n",
    "            d[str(job_id)]=res\n",
    "        vector.append(res)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_user(occurences, users, vector_size,df):\n",
    "    vector=[]\n",
    "    d={}\n",
    "    model = Word2Vec.load('model.bin')\n",
    "    nb=len(users)\n",
    "    for i,user in enumerate(users):\n",
    "        if i%10000==0:\n",
    "            print(\"progress : \",i/nb )\n",
    "        data=df.iloc[i]\n",
    "        user_id=data[\"user_id\"]\n",
    "        try:\n",
    "            res=d[str(user_id)]\n",
    "        except:\n",
    "            res=np.zeros(vector_size,)\n",
    "            n=sum(list(occurences[i].values()))\n",
    "            user_unique=list(set(user))\n",
    "            for word in user_unique:\n",
    "                try:\n",
    "                    a=model[word]\n",
    "                except:\n",
    "                    #print(word)\n",
    "                    a=None\n",
    "                if a is not None:\n",
    "                    count=occurences[i][word]\n",
    "                    w=count/n\n",
    "                    res+=w*a\n",
    "            d[str(user_id)]=res\n",
    "        vector.append(res)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress :  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lassana Diabira\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress :  0.1\n",
      "progress :  0.2\n",
      "progress :  0.3\n",
      "progress :  0.4\n",
      "progress :  0.5\n",
      "progress :  0.6\n",
      "progress :  0.7\n",
      "progress :  0.8\n",
      "progress :  0.9\n"
     ]
    }
   ],
   "source": [
    "X=get_vector_job(occurences, train_clean, 200,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress :  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lassana Diabira\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress :  0.1\n",
      "progress :  0.2\n",
      "progress :  0.3\n",
      "progress :  0.4\n",
      "progress :  0.5\n",
      "progress :  0.6\n",
      "progress :  0.7\n",
      "progress :  0.8\n",
      "progress :  0.9\n"
     ]
    }
   ],
   "source": [
    "X_user=get_vector_user(train_user_occurences, train_user_clean, 200, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 200)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_user=np.array(X_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 200)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_job_final=np.concatenate((X_train, job_characteristics.values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_job_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_user_final=np.concatenate((X_train_user, user_characteristics.values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_user_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components=2)\n",
    "#result_user = pca.fit_transform(X_train_user_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components=2)\n",
    "#result = pca.fit_transform(X_train_job_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#users=list(train[\"user_id\"].values)\n",
    "#users=[str(i) for i in users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_info_plot(df):\n",
    "    job_info=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        data=df.iloc[i]\n",
    "        title=data[\"job_title\"]\n",
    "        em_title=data[\"employer_title\"]\n",
    "        a=\"\"\n",
    "        a+=title+\" \"\n",
    "        a+=em_title+\" \"\n",
    "        job_info.append(a)\n",
    "    return job_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#infos=get_job_info_plot(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k=200\\nplt.figure(figsize=(20,20))\\nplt.scatter(result_user[:k, 0], result_user[:k, 1])\\nfor i, word in enumerate(users[:k]):\\n    plt.annotate(word, xy=(result_user[i, 0], result_user[i, 1]))\\nplt.show()'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"k=200\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.scatter(result_user[:k, 0], result_user[:k, 1])\n",
    "for i, word in enumerate(users[:k]):\n",
    "    plt.annotate(word, xy=(result_user[i, 0], result_user[i, 1]))\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title                                                Graduate Programs\n",
       "employer_title                                               Credit Suisse\n",
       "employer_sector_title                                   Investment Banking\n",
       "job_sector_title                                        Financial Services\n",
       "gender                                                                   F\n",
       "ethnicity                                                              NaN\n",
       "university_name                            Queen Mary University of London\n",
       "degree_subject_name                                              Economics\n",
       "user_preference          Consumer, FMCG & Retail Energy & Infrastructur...\n",
       "Name: 5372, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[10][['job_title','employer_title', 'employer_sector_title', 'job_sector_title', 'gender',\n",
    "       'ethnicity', 'university_name', 'degree_subject_name', 'user_preference']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_member(df, X_train, doc_id, n):\n",
    "    res=[]\n",
    "    beta=[]\n",
    "    cos=list(cosine_similarity(X_train[doc_id,:].reshape(1, -1) , X_train))[0]\n",
    "    most_similar_doc_id=np.argsort(cos)[::-1]\n",
    "    a=0\n",
    "    while cos[most_similar_doc_id[a]]>=0.9999999:\n",
    "        a+=1\n",
    "    most_similar_doc_id=most_similar_doc_id[a:]\n",
    "    res.append(df.iloc[most_similar_doc_id[0]][\"user_id\"])\n",
    "    beta.append(cos[most_similar_doc_id[0]])\n",
    "    for i in range(1,len(most_similar_doc_id)):\n",
    "        if cos[most_similar_doc_id[i]] not in beta:\n",
    "            user=df.iloc[most_similar_doc_id[i]][\"user_id\"]\n",
    "            if user not in res:\n",
    "                res.append(user)\n",
    "                beta.append(cos[most_similar_doc_id[i]])\n",
    "    print(\" user id : \", df.iloc[doc_id][\"user_id\"])\n",
    "    print(\"most similar doc : \", res[:n])\n",
    "    print(\"most similar values : \", beta[:n])\n",
    "    print(\"not similar doc : \", res[-n:][::-1])\n",
    "    print(\"not similar values : \", beta[-n:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " user id :  67420\n",
      "most similar doc :  [74199, 154654, 170872, 156985, 113673]\n",
      "most similar values :  [0.9776953517269544, 0.9748114322881276, 0.9740408504458226, 0.9732623623336111, 0.9732582954136554]\n",
      "not similar doc :  [158698, 173617, 193292, 169771, 167098]\n",
      "not similar values :  [-0.10120783467405582, 0.02071661008772877, 0.11520878805496057, 0.14089604317197513, 0.1465722137056062]\n"
     ]
    }
   ],
   "source": [
    "get_similar_member(train, X_train_user, 10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>employer_title</th>\n",
       "      <th>employer_sector_title</th>\n",
       "      <th>job_sector_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>university_name</th>\n",
       "      <th>degree_subject_name</th>\n",
       "      <th>user_preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5372</th>\n",
       "      <td>Graduate Programs</td>\n",
       "      <td>Credit Suisse</td>\n",
       "      <td>Investment Banking</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queen Mary University of London</td>\n",
       "      <td>Economics</td>\n",
       "      <td>Consumer, FMCG &amp; Retail Energy &amp; Infrastructur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>Professional Development Programme</td>\n",
       "      <td>State Street</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queen Mary University of London</td>\n",
       "      <td>Economics</td>\n",
       "      <td>Consumer, FMCG &amp; Retail Energy &amp; Infrastructur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>Management Trainee</td>\n",
       "      <td>Muntons</td>\n",
       "      <td>Consumer, FMCG &amp; Retail</td>\n",
       "      <td>Consumer, FMCG &amp; Retail</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queen Mary University of London</td>\n",
       "      <td>Economics</td>\n",
       "      <td>Consumer, FMCG &amp; Retail Energy &amp; Infrastructur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5380</th>\n",
       "      <td>Finance Graduate Program</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Consumer, FMCG &amp; Retail</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queen Mary University of London</td>\n",
       "      <td>Economics</td>\n",
       "      <td>Consumer, FMCG &amp; Retail Energy &amp; Infrastructur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5374</th>\n",
       "      <td>New Analyst Programme</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Technology: Consulting &amp; Project Management</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queen Mary University of London</td>\n",
       "      <td>Economics</td>\n",
       "      <td>Consumer, FMCG &amp; Retail Energy &amp; Infrastructur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>Counterparty Risk Management Trainee</td>\n",
       "      <td>Societe Generale</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queen Mary University of London</td>\n",
       "      <td>Economics</td>\n",
       "      <td>Consumer, FMCG &amp; Retail Energy &amp; Infrastructur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>Graduate Programme</td>\n",
       "      <td>Insight Investment</td>\n",
       "      <td>Investment &amp; Asset Management</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queen Mary University of London</td>\n",
       "      <td>Economics</td>\n",
       "      <td>Consumer, FMCG &amp; Retail Energy &amp; Infrastructur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>Graduate Analyst Positions</td>\n",
       "      <td>Evercore</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queen Mary University of London</td>\n",
       "      <td>Economics</td>\n",
       "      <td>Consumer, FMCG &amp; Retail Energy &amp; Infrastructur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 job_title      employer_title  \\\n",
       "5372                     Graduate Programs       Credit Suisse   \n",
       "5377    Professional Development Programme        State Street   \n",
       "5373                    Management Trainee             Muntons   \n",
       "5380              Finance Graduate Program              Amazon   \n",
       "5374                 New Analyst Programme       Goldman Sachs   \n",
       "5375  Counterparty Risk Management Trainee    Societe Generale   \n",
       "5379                    Graduate Programme  Insight Investment   \n",
       "5378            Graduate Analyst Positions            Evercore   \n",
       "\n",
       "              employer_sector_title  \\\n",
       "5372             Investment Banking   \n",
       "5377             Financial Services   \n",
       "5373        Consumer, FMCG & Retail   \n",
       "5380        Consumer, FMCG & Retail   \n",
       "5374             Financial Services   \n",
       "5375             Financial Services   \n",
       "5379  Investment & Asset Management   \n",
       "5378             Financial Services   \n",
       "\n",
       "                                 job_sector_title gender ethnicity  \\\n",
       "5372                           Financial Services      F       NaN   \n",
       "5377                           Financial Services      F       NaN   \n",
       "5373                      Consumer, FMCG & Retail      F       NaN   \n",
       "5380                           Financial Services      F       NaN   \n",
       "5374  Technology: Consulting & Project Management      F       NaN   \n",
       "5375                           Financial Services      F       NaN   \n",
       "5379                           Financial Services      F       NaN   \n",
       "5378                           Financial Services      F       NaN   \n",
       "\n",
       "                      university_name degree_subject_name  \\\n",
       "5372  Queen Mary University of London           Economics   \n",
       "5377  Queen Mary University of London           Economics   \n",
       "5373  Queen Mary University of London           Economics   \n",
       "5380  Queen Mary University of London           Economics   \n",
       "5374  Queen Mary University of London           Economics   \n",
       "5375  Queen Mary University of London           Economics   \n",
       "5379  Queen Mary University of London           Economics   \n",
       "5378  Queen Mary University of London           Economics   \n",
       "\n",
       "                                        user_preference  \n",
       "5372  Consumer, FMCG & Retail Energy & Infrastructur...  \n",
       "5377  Consumer, FMCG & Retail Energy & Infrastructur...  \n",
       "5373  Consumer, FMCG & Retail Energy & Infrastructur...  \n",
       "5380  Consumer, FMCG & Retail Energy & Infrastructur...  \n",
       "5374  Consumer, FMCG & Retail Energy & Infrastructur...  \n",
       "5375  Consumer, FMCG & Retail Energy & Infrastructur...  \n",
       "5379  Consumer, FMCG & Retail Energy & Infrastructur...  \n",
       "5378  Consumer, FMCG & Retail Energy & Infrastructur...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train[\"user_id\"]==67420][['job_title','employer_title', 'employer_sector_title', 'job_sector_title', 'gender',\n",
    "       'ethnicity', 'university_name', 'degree_subject_name', 'user_preference']].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# similar users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>employer_title</th>\n",
       "      <th>employer_sector_title</th>\n",
       "      <th>job_sector_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>university_name</th>\n",
       "      <th>degree_subject_name</th>\n",
       "      <th>user_preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23232</th>\n",
       "      <td>Deloitte Graduate Fast Track Programme 2018</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>Accounting, Tax &amp; Audit</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University of Birmingham</td>\n",
       "      <td>Economics</td>\n",
       "      <td>Commercial Law Consumer, FMCG &amp; Retail Educati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23231</th>\n",
       "      <td>Asset &amp; Wealth Management - Wealth Management ...</td>\n",
       "      <td>J.P. Morgan</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Investment &amp; Asset Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University of Birmingham</td>\n",
       "      <td>Economics</td>\n",
       "      <td>Commercial Law Consumer, FMCG &amp; Retail Educati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23229</th>\n",
       "      <td>Investment Graduate Scheme</td>\n",
       "      <td>M&amp;G Investments</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University of Birmingham</td>\n",
       "      <td>Economics</td>\n",
       "      <td>Commercial Law Consumer, FMCG &amp; Retail Educati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23227</th>\n",
       "      <td>Graduate Programs</td>\n",
       "      <td>Credit Suisse</td>\n",
       "      <td>Investment Banking</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University of Birmingham</td>\n",
       "      <td>Economics</td>\n",
       "      <td>Commercial Law Consumer, FMCG &amp; Retail Educati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23228</th>\n",
       "      <td>New Analyst Programme</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Technology: Consulting &amp; Project Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University of Birmingham</td>\n",
       "      <td>Economics</td>\n",
       "      <td>Commercial Law Consumer, FMCG &amp; Retail Educati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               job_title   employer_title  \\\n",
       "23232        Deloitte Graduate Fast Track Programme 2018         Deloitte   \n",
       "23231  Asset & Wealth Management - Wealth Management ...      J.P. Morgan   \n",
       "23229                         Investment Graduate Scheme  M&G Investments   \n",
       "23227                                  Graduate Programs    Credit Suisse   \n",
       "23228                              New Analyst Programme    Goldman Sachs   \n",
       "\n",
       "      employer_sector_title                             job_sector_title  \\\n",
       "23232            Consulting                      Accounting, Tax & Audit   \n",
       "23231    Financial Services                Investment & Asset Management   \n",
       "23229    Financial Services                           Financial Services   \n",
       "23227    Investment Banking                           Financial Services   \n",
       "23228    Financial Services  Technology: Consulting & Project Management   \n",
       "\n",
       "       gender ethnicity           university_name degree_subject_name  \\\n",
       "23232  Female       NaN  University of Birmingham           Economics   \n",
       "23231  Female       NaN  University of Birmingham           Economics   \n",
       "23229  Female       NaN  University of Birmingham           Economics   \n",
       "23227  Female       NaN  University of Birmingham           Economics   \n",
       "23228  Female       NaN  University of Birmingham           Economics   \n",
       "\n",
       "                                         user_preference  \n",
       "23232  Commercial Law Consumer, FMCG & Retail Educati...  \n",
       "23231  Commercial Law Consumer, FMCG & Retail Educati...  \n",
       "23229  Commercial Law Consumer, FMCG & Retail Educati...  \n",
       "23227  Commercial Law Consumer, FMCG & Retail Educati...  \n",
       "23228  Commercial Law Consumer, FMCG & Retail Educati...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train[\"user_id\"]==74199][['job_title','employer_title', 'employer_sector_title', 'job_sector_title', 'gender',\n",
    "       'ethnicity', 'university_name', 'degree_subject_name', 'user_preference']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>employer_title</th>\n",
       "      <th>employer_sector_title</th>\n",
       "      <th>job_sector_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>university_name</th>\n",
       "      <th>degree_subject_name</th>\n",
       "      <th>user_preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85876</th>\n",
       "      <td>Finance Graduate Program</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Consumer, FMCG &amp; Retail</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Female</td>\n",
       "      <td>White/White British</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>History</td>\n",
       "      <td>Investment Banking Insurance &amp; Risk Management...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85864</th>\n",
       "      <td>Graduate Programs</td>\n",
       "      <td>Credit Suisse</td>\n",
       "      <td>Investment Banking</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Female</td>\n",
       "      <td>White/White British</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>History</td>\n",
       "      <td>Investment Banking Insurance &amp; Risk Management...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85869</th>\n",
       "      <td>Investment Banking Analyst Program - Full-time</td>\n",
       "      <td>J.P. Morgan</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Investment Banking</td>\n",
       "      <td>Female</td>\n",
       "      <td>White/White British</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>History</td>\n",
       "      <td>Investment Banking Insurance &amp; Risk Management...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85867</th>\n",
       "      <td>New Analyst Programme</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Technology: Consulting &amp; Project Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>White/White British</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>History</td>\n",
       "      <td>Investment Banking Insurance &amp; Risk Management...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85875</th>\n",
       "      <td>Internships</td>\n",
       "      <td>Jane Street</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Technology: Consulting &amp; Project Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>White/White British</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>History</td>\n",
       "      <td>Investment Banking Insurance &amp; Risk Management...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85873</th>\n",
       "      <td>Graduate Analysts Programme</td>\n",
       "      <td>Nomura</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Technology: Consulting &amp; Project Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>White/White British</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>History</td>\n",
       "      <td>Investment Banking Insurance &amp; Risk Management...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85860</th>\n",
       "      <td>Graduate Programme</td>\n",
       "      <td>DC Advisory Partners Limited</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Female</td>\n",
       "      <td>White/White British</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>History</td>\n",
       "      <td>Investment Banking Insurance &amp; Risk Management...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title  \\\n",
       "85876                        Finance Graduate Program   \n",
       "85864                               Graduate Programs   \n",
       "85869  Investment Banking Analyst Program - Full-time   \n",
       "85867                           New Analyst Programme   \n",
       "85875                                     Internships   \n",
       "85873                     Graduate Analysts Programme   \n",
       "85860                              Graduate Programme   \n",
       "\n",
       "                     employer_title    employer_sector_title  \\\n",
       "85876                        Amazon  Consumer, FMCG & Retail   \n",
       "85864                 Credit Suisse       Investment Banking   \n",
       "85869                   J.P. Morgan       Financial Services   \n",
       "85867                 Goldman Sachs       Financial Services   \n",
       "85875                   Jane Street       Financial Services   \n",
       "85873                        Nomura       Financial Services   \n",
       "85860  DC Advisory Partners Limited       Financial Services   \n",
       "\n",
       "                                  job_sector_title  gender  \\\n",
       "85876                           Financial Services  Female   \n",
       "85864                           Financial Services  Female   \n",
       "85869                           Investment Banking  Female   \n",
       "85867  Technology: Consulting & Project Management  Female   \n",
       "85875  Technology: Consulting & Project Management  Female   \n",
       "85873  Technology: Consulting & Project Management  Female   \n",
       "85860                           Financial Services  Female   \n",
       "\n",
       "                 ethnicity          university_name degree_subject_name  \\\n",
       "85876  White/White British  University of Cambridge             History   \n",
       "85864  White/White British  University of Cambridge             History   \n",
       "85869  White/White British  University of Cambridge             History   \n",
       "85867  White/White British  University of Cambridge             History   \n",
       "85875  White/White British  University of Cambridge             History   \n",
       "85873  White/White British  University of Cambridge             History   \n",
       "85860  White/White British  University of Cambridge             History   \n",
       "\n",
       "                                         user_preference  \n",
       "85876  Investment Banking Insurance & Risk Management...  \n",
       "85864  Investment Banking Insurance & Risk Management...  \n",
       "85869  Investment Banking Insurance & Risk Management...  \n",
       "85867  Investment Banking Insurance & Risk Management...  \n",
       "85875  Investment Banking Insurance & Risk Management...  \n",
       "85873  Investment Banking Insurance & Risk Management...  \n",
       "85860  Investment Banking Insurance & Risk Management...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train[\"user_id\"]==154654][['job_title','employer_title', 'employer_sector_title', 'job_sector_title', 'gender',\n",
    "       'ethnicity', 'university_name', 'degree_subject_name', 'user_preference']].tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# not similar users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>employer_title</th>\n",
       "      <th>employer_sector_title</th>\n",
       "      <th>job_sector_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>university_name</th>\n",
       "      <th>degree_subject_name</th>\n",
       "      <th>user_preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106992</th>\n",
       "      <td>Herbert Smith Freehills Event Dates 2017-2018</td>\n",
       "      <td>Herbert Smith Freehills</td>\n",
       "      <td>Commercial Law</td>\n",
       "      <td>Commercial Law</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian/Asian British</td>\n",
       "      <td>University of Warwick</td>\n",
       "      <td>Engineering - Mechanical</td>\n",
       "      <td>Commercial Law</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title  \\\n",
       "106992  Herbert Smith Freehills Event Dates 2017-2018   \n",
       "\n",
       "                 employer_title employer_sector_title job_sector_title gender  \\\n",
       "106992  Herbert Smith Freehills        Commercial Law   Commercial Law   Male   \n",
       "\n",
       "                  ethnicity        university_name       degree_subject_name  \\\n",
       "106992  Asian/Asian British  University of Warwick  Engineering - Mechanical   \n",
       "\n",
       "        user_preference  \n",
       "106992  Commercial Law   "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train[\"user_id\"]==158698][['job_title','employer_title', 'employer_sector_title', 'job_sector_title', 'gender',\n",
    "       'ethnicity', 'university_name', 'degree_subject_name', 'user_preference']].tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>employer_title</th>\n",
       "      <th>employer_sector_title</th>\n",
       "      <th>job_sector_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>university_name</th>\n",
       "      <th>degree_subject_name</th>\n",
       "      <th>user_preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26048</th>\n",
       "      <td>Herbert Smith Freehills Event Dates 2017-2018</td>\n",
       "      <td>Herbert Smith Freehills</td>\n",
       "      <td>Commercial Law</td>\n",
       "      <td>Commercial Law</td>\n",
       "      <td>Female</td>\n",
       "      <td>White/White British</td>\n",
       "      <td>University College London (UCL)</td>\n",
       "      <td>Translation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26047</th>\n",
       "      <td>Vacation Scheme</td>\n",
       "      <td>Gowling WLG</td>\n",
       "      <td>Commercial Law</td>\n",
       "      <td>Commercial Law</td>\n",
       "      <td>Female</td>\n",
       "      <td>White/White British</td>\n",
       "      <td>University College London (UCL)</td>\n",
       "      <td>Translation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title           employer_title  \\\n",
       "26048  Herbert Smith Freehills Event Dates 2017-2018  Herbert Smith Freehills   \n",
       "26047                                Vacation Scheme              Gowling WLG   \n",
       "\n",
       "      employer_sector_title job_sector_title  gender            ethnicity  \\\n",
       "26048        Commercial Law   Commercial Law  Female  White/White British   \n",
       "26047        Commercial Law   Commercial Law  Female  White/White British   \n",
       "\n",
       "                       university_name degree_subject_name user_preference  \n",
       "26048  University College London (UCL)         Translation             NaN  \n",
       "26047  University College London (UCL)         Translation             NaN  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train[\"user_id\"]==173617][['job_title','employer_title', 'employer_sector_title', 'job_sector_title', 'gender',\n",
    "       'ethnicity', 'university_name', 'degree_subject_name', 'user_preference']].tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>employer_title</th>\n",
       "      <th>employer_sector_title</th>\n",
       "      <th>job_sector_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>university_name</th>\n",
       "      <th>degree_subject_name</th>\n",
       "      <th>user_preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125035</th>\n",
       "      <td>Campus Ambassadors</td>\n",
       "      <td>Reed Smith</td>\n",
       "      <td>Commercial Law</td>\n",
       "      <td>Commercial Law</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Durham University</td>\n",
       "      <td>History and Spanish</td>\n",
       "      <td>Commercial Law</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 job_title employer_title employer_sector_title  \\\n",
       "125035  Campus Ambassadors     Reed Smith        Commercial Law   \n",
       "\n",
       "       job_sector_title  gender ethnicity    university_name  \\\n",
       "125035   Commercial Law  Female       NaN  Durham University   \n",
       "\n",
       "        degree_subject_name  user_preference  \n",
       "125035  History and Spanish  Commercial Law   "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train[\"user_id\"]==98253][['job_title','employer_title', 'employer_sector_title', 'job_sector_title', 'gender',\n",
    "       'ethnicity', 'university_name', 'degree_subject_name', 'user_preference']].tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_doc(X_train, doc_id, n):\n",
    "    res=[]\n",
    "    beta=[]\n",
    "    cos=list(cosine_similarity(X_train[doc_id,:].reshape(1, -1) , X_train))[0]\n",
    "    most_similar_doc_id=np.argsort(cos)[::-1]\n",
    "    a=0\n",
    "    while cos[most_similar_doc_id[a]]>=0.9999999:\n",
    "        a+=1\n",
    "    most_similar_doc_id=most_similar_doc_id[a:]\n",
    "    res.append(most_similar_doc_id[0])\n",
    "    beta.append(cos[most_similar_doc_id[0]])\n",
    "    for i in range(1,len(most_similar_doc_id)):\n",
    "        if cos[most_similar_doc_id[i]] not in beta:\n",
    "            res.append(most_similar_doc_id[i])\n",
    "            beta.append(cos[most_similar_doc_id[i]])\n",
    "    print(\"most similar doc : \", res[:n])\n",
    "    print(\"most similar values : \", beta[:n])\n",
    "    print(\"not similar doc : \", res[-n:][::-1])\n",
    "    print(\"not similar values : \", beta[-n:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_similarity(x):\n",
    "    res=[] \n",
    "    for content in x:\n",
    "        content=content.replace(\",\",\"\").replace(\"-\",\" \").replace(\"  \",\" \")\n",
    "        content=content.replace(\"(\",\"\").replace(\")\",\"\").replace(\" - \",\" \").replace(\" / \",\" \").replace(\"/\",\" \").replace(\"   \",\"\")\n",
    "        content=content.replace(\"&bull;\",\"\\r\\n \").replace(\"bull;\",\"\\r\\n \").replace(\"\\r\\r\\n\\t\",\" \").replace(\"\\r\\r\\n\",\" \")\n",
    "        content=content.replace(\"\\r\\r\\n\\r\\r\\n\",\" \").replace(\"...\",\" \").replace(\"&#39;s\",\"\").replace(\":\",\"\")\n",
    "        content=content.replace(\"&eacute;\",\"e\").replace(\"&lsquo;\",\"\").replace(\"lsquo;\",\"\").replace(\"&#39;\",\"\").replace(\"#39;s\",\"\")\n",
    "        content=content.replace(\"&nbsp;\",\" \").replace(\"nbsp;\",\" \").replace(\"&#39;\",\"\").replace(\"amp;\",\"\").replace(\"&middot;\",\"\")\n",
    "        content=content.replace(\".\",\" \").replace(\",\",\"\").replace(\"?\",\" \").replace(\"!\",\"\").replace(\"  \",\" \").replace(\"middot;\",\"\")\n",
    "        content=content.replace(\"&rsquo;\",\"\").replace(\"rsquo;\",\" \").replace(\"\\t\",\" \").replace(\"\\r\\n\\r\\n\",\"\").replace(\" \\r\\n \",\"\")\n",
    "        content=content.replace(\"&ndash;\",\" \").replace(\"ndash;\",\" \").replace(\"\\r\\n\\r\\n\",\" \").replace(\" \\r\\n \",\" \").replace(\"\\r\\n\",\" \")\n",
    "        content=content.replace(\"\\r\",\" \").replace(\"  \",\"\").replace(\"   \",\"\").replace(\"  \",\"\").replace(\"   \",\"\")\n",
    "        content=content.replace(\"(\",\"\").replace(\")\",\"\").replace(\" - \",\" \").replace(\" / \",\" \").replace(\"/\",\" \").replace(\"   \",\"\")\n",
    "        content=re.sub('<.*?>',\"\",content , flags=re.DOTALL)\n",
    "        res.append(content)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_similarity=clean_similarity(train_job_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most similar doc :  [69307, 77022, 42907, 75232, 26673]\n",
      "most similar values :  [0.939602703820889, 0.9389237348812738, 0.9260504443605474, 0.9151344383612695, 0.8944081509168142]\n",
      "not similar doc :  [8555, 74064, 60679, 69981, 9685]\n",
      "not similar values :  [-0.23217292623603597, -0.1338385141763883, -0.03124304928293687, 0.07172323018953197, 0.1197311342829278]\n"
     ]
    }
   ],
   "source": [
    "get_similar_doc(X_train, 10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Graduate Programs Financial Services Training We provide a rich development environment by combining formal learning on the job practice and mentoring  We believe soft skills are crucial to our business Thats why our training programs also develop your presentation communication and interpersonal skills You can expect exceptional support with any mandatory regulatory training and exams  Throughout your training youll have exposure to senior managers colleagues and peers across the bank at all levels which will add new insights and fresh perspectives to your understanding of what we do and what you need to do well at Credit Suisse   Receive technical and financial training from some of the industrys top instructors  Listen to business presentations from Credit Suisse professionals  Participate in philanthropic and teambuilding events  Attend social and networking events with peers and Credit Suisse professionals  Prepare for FCA regulatory training and exams  Rotate through the Shared Services and Investment Banking Operation departments  Roles Roles are available in  Investment Banking Equities Fixed Income Global Market Solutions Operations Alternate Investments Information Technology Finance CFO COO Change Program Services  Who is it for  Our Full time Analyst Programs are open to undergraduates and students studying for a Masters degree in any discipline  Credit Suisse Investment Banking Credit Suisse is a global financial services company providing a broad range of advisory services solutions and products in Private Banking & Wealth Management and Investment Banking to companies institutions and private clients Credit Suisse is active in more than 50 countries and employs over 46000 people  As a stable company with a long banking tradition we are one of the most respected banks in the world We offer entry level hiring programs in a variety of business areas Our programs give you the chance to make a difference from day one and provide world class training and support to help you to develop into a future business leader And throughout your career with us you will benefit from cross business and international mobility opportunities We look for people with a wide range of experiences interests and degrees who will add fresh perspectives to our business A career with us means that you can help shape our future  Dont forget to cite Bright Network on your Credit Suisse application form theyre keen to hear from our members'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_similarity[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summer Internship Programs Financial Services Summer Internship Program Our Summer Internship Program is designed to offer real insight into our business The program typically lasts ten weeks and is one of the most in depth internships within the financial services industry From day one youll be part of the team Youll face real challenges have client exposure enjoy real achievements and have your talents recognized every step of the way  Youll be responsible for projects and tasks that matter to the business Youll grow in knowledge skills and confidence Above all youll experience the team spirit that makes Credit Suisse such a special place to work Our program managers will help guide you through your summer experience and each intern is assigned a mentor and a buddy so youll have all the support you need  If you show real potential and demonstrate exceptional performance during your time with us you may be offered a full time position for the following year   Train in a comprehensive ten week global program Receive up to five days of training in London Learn from on the job and classroom based training Network across the Bank through cross divisional and division specific events Participate in philanthropic and teambuilding events Gain an understanding of the market data and technology tools youll use during training Listen to business presentations from our internal professionals who apply industry knowledge to our Credit Suisse environment  Participate in a formal mentoring program Attend structured review and feedback sessions  Opportunities are available in  Asset Management Equities Research Fixed Income Research Global Markets Sales and Trading Investment Banking and Capital Markets Technology IT    Credit Suisse Investment Banking Credit Suisse is a global financial services company providing a broad range of advisory services solutions and products in Private Banking & Wealth Management and Investment Banking to companies institutions and private clients Credit Suisse is active in more than 50 countries and employs over 46000 people  As a stable company with a long banking tradition we are one of the most respected banks in the world We offer entry level hiring programs in a variety of business areas Our programs give you the chance to make a difference from day one and provide world class training and support to help you to develop into a future business leader And throughout your career with us you will benefit from cross business and international mobility opportunities We look for people with a wide range of experiences interests and degrees who will add fresh perspectives to our business A career with us means that you can help shape our future  Dont forget to cite Bright Network on your Credit Suisse application form theyre keen to hear from our members'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_similarity[69307]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# not similar jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TPP Top 50 Oxford events Technology Consulting & Project Management On Tuesday 31st October we are hosting evening reception with free drinks and food at the Bodleian Library featuring renowned stand up comedian Sean Lock As well as live entertainment the reception will give you the opportunity to chat to TPP Oxford alumni and find out what it is like to work at the heart of a fast paced technology company  Job interviews will take place at the Examination Schools in Oxford on Thursday 2nd and Friday 3rd November giving you the opportunity to walk away with a &pound;40000 graduate job by the end of the week Oxford Events October  17th October Drinks reception at Lady Margaret Hall When 7 30pm 10pm  Where Talbot Hall 18th October Physics Society science themed quiz night free pizza & drinks When 5 15pm Where Physics Society 18th October Oxford Union event with JJ Abrams When 8pm Where Oxford Union 23rd October Evening reception at St Hughs College When 7 30pm 10pm Where Wordsworth Room  24th October TPP free food giveaway at the Oxford Stats Department  When 11am 12pm Where Outside the Oxford Stats Department  24th October Tech Talk The Future of Digital Medicine with CEO Frank Hester When 1pm Where Lecture Theatre A Computer Science Department 26th October Networking drinks at St Cross College When 7pm 10pm Where Saugman Common Room 31st October An Evening of Comedy with Sean Lock When 7pm 10pm Where Divinity School Bodliean Library  November  1st November Invariants Maths Society quiz night free pizza & drinks When 7pm Where Maths Institutes common room 2nd & 3rd November Interviews When All day Where Examinations School  All our events are casual so dont feel the need to dress up TPP Technology IT & Software Development TPP is a UK based IT company dedicated to delivering world class healthcare software through our innovative products; SystmOne SystmConnect SystmInsight and SystmOnline Our philosophy is to join up healthcare based on a shared electronic medical record improving access to clinical data and empowering patients to take part in their care In 2014 and 2015 TPP placed first in the Sunday Times 100 Best Small Companies to Work For Most recently we were named Top Company For Graduates To Work For 2016 17&prime; by TheJobCrowd  Were unusual in that we dont require any experience for any of our graduate positions and many of our software developers have never programmed before We look for bright and geeky graduates from the best universities The subject you studied doesnt matter all we ask is that you have a passion for problem solving and an inquisitive mind  Dont forget to cite Bright Network on your TPP application form theyre keen to hear from our members'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_similarity[74064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((X_train, X_train_user), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=data.reshape(data.shape[0],data.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 400)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lassana Diabira\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(data, data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 400)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = Input(shape=(data.shape[1],))\n",
    "encoded = Dense(500, activation='relu')(input_data)\n",
    "encoded = Dense(300, activation='relu')(encoded)\n",
    "encoded = Dense(200, activation='relu')(encoded)\n",
    "encoded = Dense(100, activation='relu')(encoded)\n",
    "encoded = Dense(50, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(100, activation='relu')(encoded)\n",
    "decoded = Dense(200, activation='relu')(decoded)\n",
    "decoded = Dense(300, activation='relu')(decoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(400, activation='linear')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/100\n",
      "80000/80000 [==============================] - 142s 2ms/step - loss: 0.0157 - val_loss: 0.0118\n",
      "Epoch 2/100\n",
      "80000/80000 [==============================] - 97s 1ms/step - loss: 0.0109 - val_loss: 0.0098- ETA: 8s - loss: 0.011 - ETA: 8s - - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.010\n",
      "Epoch 3/100\n",
      "80000/80000 [==============================] - 99s 1ms/step - loss: 0.0092 - val_loss: 0.0085\n",
      "Epoch 4/100\n",
      "80000/80000 [==============================] - 85s 1ms/step - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 5/100\n",
      "80000/80000 [==============================] - 102s 1ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 6/100\n",
      "80000/80000 [==============================] - 106s 1ms/step - loss: 0.0069 - val_loss: 0.0065 0 - ETA: 4s - - E - ETA:\n",
      "Epoch 7/100\n",
      "80000/80000 [==============================] - 102s 1ms/step - loss: 0.0065 - val_loss: 0.0062 - - ETA: 6s - l - ETA: 6s - loss: 0.00 - ETA: 5s -  - ETA: 5s - loss: 0.0 - ETA: 4s - loss: - E - ETA: 3s - loss: 0.006 - ETA: 3s - loss: - ET\n",
      "Epoch 8/100\n",
      "80000/80000 [==============================] - 101s 1ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 9/100\n",
      "80000/80000 [==============================] - 104s 1ms/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 10/100\n",
      "80000/80000 [==============================] - 103s 1ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 11/100\n",
      "80000/80000 [==============================] - 102s 1ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 12/100\n",
      "80000/80000 [==============================] - 102s 1ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 13/100\n",
      "80000/80000 [==============================] - 98s 1ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 14/100\n",
      "80000/80000 [==============================] - 101s 1ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 15/100\n",
      "80000/80000 [==============================] - 101s 1ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 16/100\n",
      "80000/80000 [==============================] - 101s 1ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 17/100\n",
      "80000/80000 [==============================] - 99s 1ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 18/100\n",
      "80000/80000 [==============================] - 84s 1ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 19/100\n",
      "80000/80000 [==============================] - 140s 2ms/step - loss: 0.0045 - val_loss: 0.0045A: 3s - \n",
      "Epoch 20/100\n",
      "80000/80000 [==============================] - 140s 2ms/step - loss: 0.0045 - val_loss: 0.0044 ETA: 1s - los - ETA: 1s \n",
      "Epoch 21/100\n",
      "80000/80000 [==============================] - 140s 2ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 22/100\n",
      "80000/80000 [==============================] - 141s 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 23/100\n",
      "80000/80000 [==============================] - 148s 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "80000/80000 [==============================] - 157s 2ms/step - loss: 0.0042 - val_loss: 0.0041 2s - loss: 0.004 - ETA - ETA: 0s - loss:\n",
      "Epoch 25/100\n",
      "80000/80000 [==============================] - 157s 2ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 26/100\n",
      "80000/80000 [==============================] - 158s 2ms/step - loss: 0.0040 - val_loss: 0.0041 - lo\n",
      "Epoch 27/100\n",
      "80000/80000 [==============================] - 142s 2ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 28/100\n",
      "80000/80000 [==============================] - 150s 2ms/step - loss: 0.0039 - val_loss: 0.0038 - -  - ETA: 0s - loss: 0.\n",
      "Epoch 29/100\n",
      "80000/80000 [==============================] - 147s 2ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 30/100\n",
      "80000/80000 [==============================] - 149s 2ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 31/100\n",
      "80000/80000 [==============================] - 142s 2ms/step - loss: 0.0038 - val_loss: 0.0037: 5s - loss:  - ETA - ET\n",
      "Epoch 32/100\n",
      "80000/80000 [==============================] - 157s 2ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 33/100\n",
      "80000/80000 [==============================] - 158s 2ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 34/100\n",
      " 1650/80000 [..............................] - ETA: 2:14 - loss: 0.0037"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-d551923955dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                 validation_data=(x_test, x_test))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder = Model(input_data, decoded)\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=50,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history=autoencoder.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07818252,  0.37438182,  0.02957342,  0.27553629, -0.05103732,\n",
       "        0.11236704,  0.25922861, -0.18485701,  0.08447592,  0.01387077,\n",
       "       -0.1347849 , -0.16051411,  0.65449322, -0.10759036,  0.47460948,\n",
       "       -0.1078515 ,  0.01020028, -0.1280845 ,  0.0587196 ,  0.14966337])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0414155 ,  0.31699526, -0.10608255,  0.2607403 , -0.10131958,\n",
       "       -0.01853166,  0.2817322 , -0.24203044,  0.05328552, -0.0076244 ,\n",
       "       -0.12371764, -0.16409057,  0.56412756,  0.00402433,  0.24327245,\n",
       "       -0.24379684,  0.0414675 , -0.074757  ,  0.04043657,  0.26335266],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003328874317530843"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(preds, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights(\"autoencoder.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
